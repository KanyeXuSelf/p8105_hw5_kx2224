---
title: "kx2224_hw5"
author: "Kx2224"
date: "2024-11-15"
output: github_document
---

```{r}
library(dplyr)
library(broom)
library(purrr)
library(tidyr)
library(ggplot2)
library(tidyverse)
library(knitr)
```

## Problem 1
```{r}
# build the function
has_duplicate_birthday <- function(group_size) {
  birthdays <- sample(1:365, group_size, replace = TRUE)
  return(any(duplicated(birthdays)))
}
```

```{r}
# make the experiment
group_sizes <- 2:50
simulations <- 10000

# Run simulations and calculate probabilities
set.seed(42) 
probabilities <- sapply(group_sizes, function(size) {
  mean(replicate(simulations, has_duplicate_birthday(size)))
})
```

```{r}
# Plot the results
plot(group_sizes, probabilities, type = "o", pch = 16, lty = 1,
     xlab = "Group Size", ylab = "Probability of Shared Birthday",
     main = "Birthday Paradox Simulation",
     ylim = c(0, 1))
```
As the group size increases, the probability of at least two people sharing a birthday increases significantly. From the result, we can find that, with just 23 people, the probability exceeds 50%!

## Problem2
```{r}
library(broom)
```

```{r}
# Define parameters
n <- 30
sigma <- 5
mu_values <- c(0, 1, 2, 3, 4, 5, 6)
alpha <- 0.05
simulations <- 5000
```

```{r}
power_results <- data.frame()
mean_estimates <- data.frame()

# Simulation loop over different values of mu
for (mu in mu_values) {
  rejections <- 0
  estimates <- c()
  estimates_rejected <- c()
  
  for (i in 1:simulations) {
    data <- rnorm(n, mean = mu, sd = sigma)
    
    test_result <- t.test(data, mu = 0)
    test_tidy <- tidy(test_result)
    
    estimate <- test_tidy$estimate
    p_value <- test_tidy$p.value
    
    estimates <- c(estimates, estimate)
    
    if (p_value < alpha) {
      rejections <- rejections + 1
      estimates_rejected <- c(estimates_rejected, estimate)
    }
  }
  
  power <- rejections / simulations
  power_results <- rbind(power_results, data.frame(mu = mu, power = power))
  mean_estimates <- rbind(mean_estimates, 
                          data.frame(mu = mu, mean_estimate = mean(estimates), 
                                     mean_estimate_rejected = mean(estimates_rejected, na.rm = TRUE)))
}
```

### Question1
```{r}
plot(power_results$mu, power_results$power, type = "o", pch = 16, col = "blue",
     xlab = "True Value of Mu", ylab = "Power (Proportion of Null Rejections)",
     main = "Power vs Effect Size (Mu)")

```
This plot shows that as the true effect size ($\mu$) increases, the power of the test increases. This is because larger effect sizes make it easier to detect a difference from zero, thus increasing the power. 

### Question 2
```{r}
plot(mean_estimates$mu, mean_estimates$mean_estimate, type = "o", pch = 16, col = "blue",
     xlab = "True Value of Mu", ylab = "Mean Estimate of Mu",
     main = "Mean Estimate of Mu vs True Mu")
points(mean_estimates$mu, mean_estimates$mean_estimate_rejected, type = "o", pch = 16, col = "red")
legend("topleft", legend = c("Mean Estimate (All)", "Mean Estimate (Rejected Only)"),
       col = c("blue", "red"), pch = 16)
```

This plot shows the average estimate of mu across all simulations and specifically for cases where the null was rejected. The average estimate for the rejected cases is higher than for all cases, as expected, since we only consider cases where the test found a significant effect.


## Problem 3
```{r}
homicide_data = read_csv("homicide-data.csv") |>
  arrange(reported_date)
head(homicide_data)
```
### Create city_state variable and Describe
```{r}
homicide_data <- homicide_data %>%
  mutate(city_state = paste(city, state, sep = ", ")) %>%
  group_by(city_state) %>%
  summarize(
    total_homicides = n(),
    unsolved_homicides = sum(disposition %in% c("Closed without arrest", "Open/No arrest"))
  )
```

Description of the aggregated data:
- `city_state`: Combined city and state information (e.g., Baltimore, MD).
- `total_homicides`: Total number of homicides reported in each city.
- `unsolved_homicides`: Number of homicides that remain unsolved (disposition marked as 'Closed without arrest' or 'Open/No arrest').

```{r}
print(homicide_data)
```
### Baltimore test
```{r}
baltimore_data <- filter(homicide_data, city_state == "Baltimore, MD")
baltimore_test <- prop.test(baltimore_data$unsolved_homicides, baltimore_data$total_homicides)
baltimore_results <- broom::tidy(baltimore_test)
print(baltimore_results)
```
For the city of Baltimore, MD, a hypothesis test was conducted to estimate the proportion of unsolved homicides. The estimated proportion of unsolved homicides is `r round(baltimore_results$estimate, 3)` with a 95% confidence interval ranging from `r round(baltimore_results$conf.low, 3)` to `r round(baltimore_results$conf.high, 3)`. 

The p-value for the test is `r round(baltimore_results$p.value, 4)`, indicating that there is `r ifelse(baltimore_results$p.value < 0.05, "statistically significant", "not statistically significant")` evidence to suggest that the true proportion of unsolved homicides differs from 0.

### Create CI for all cities
```{r}
allcity_prop_test_results <- homicide_data %>%
  mutate(
    test_results = purrr::map2(unsolved_homicides, total_homicides, ~ prop.test(.x, .y)),
    test_tidy = purrr::map(test_results, broom::tidy)
  ) %>%
  unnest(test_tidy) %>%
  select(city_state, estimate, conf.low, conf.high)
```

```{r}
allcity_prop_test_results
```

```{r}
# Plotting the estimates and confidence intervals
ggplot(allcity_prop_test_results, aes(x = reorder(city_state, estimate), y = estimate)) +
  geom_point(size = 1) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  coord_flip() +
  labs(
    title = "Proportion of Unsolved Homicides by City",
    x = "City",
    y = "Proportion of Unsolved Homicides"
  ) +
  theme_minimal()+theme(axis.text.y = element_text(size = 9))
```








